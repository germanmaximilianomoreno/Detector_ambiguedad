{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99xt7IDueD3C"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Paso 0: Importar librerías\n",
        "# -----------------------------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Paso 1: Cargar dataset de entrenamiento\n",
        "# -----------------------------\n",
        "\n",
        "df = pd.read_excel(\"dataset_entrenamiento_1053.ods\", engine=\"odf\")\n",
        "\n",
        "# Normalizar la columna 'tipo_ambiguedad' (minúsculas, sin espacios)\n",
        "df[\"tipo_ambiguedad\"] = df[\"tipo_ambiguedad\"].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Tipos que se consideran ambiguos\n",
        "tipos_ambiguos = [\"semántica\", \"pragmática\", \"sintáctica\", \"léxica\",\n",
        "                  \"semantica\", \"pragmatica\", \"sintantica\", \"lexica\"]\n",
        "\n",
        "# Crear columna 'ambiguo' (1 si es ambiguo, 0 si no)\n",
        "df[\"ambiguo\"] = df[\"tipo_ambiguedad\"].apply(lambda x: 1 if x in tipos_ambiguos else 0)\n",
        "\n",
        "# Crear la estructura corpus_requerimientos\n",
        "corpus_requerimientos = [\n",
        "    {\"requerimiento\": req, \"ambiguo\": amb}\n",
        "    for req, amb in zip(df[\"requerimiento\"], df[\"ambiguo\"])\n",
        "]\n",
        "\n",
        "# Crear listas separadas\n",
        "requerimientos = [r[\"requerimiento\"] for r in corpus_requerimientos]\n",
        "labels = [r[\"ambiguo\"] for r in corpus_requerimientos]"
      ],
      "metadata": {
        "id": "QB74asNweRVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Paso 3: Entrenar el modelo y graficamos los resultados\n",
        "# -----------------------------\n",
        "\n",
        "# Fijar semilla global\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Generar embeddings\n",
        "embedder = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "X = embedder.encode(requerimientos)\n",
        "Y = np.array(labels)\n",
        "\n",
        "# Dividir datos de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=SEED, stratify=Y\n",
        ")\n",
        "\n",
        "# Crear Red neuronal profunda para Clasificación Binaria\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Salida binaria con sigmoid\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Definir EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Entrenamiento con EarlyStopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=110,\n",
        "    batch_size=2,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# Visualizar los resulatdos de Loss y Accuracy\n",
        "\n",
        "# Loss\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['loss'], label='Loss de Entrenamiento', color='red')\n",
        "plt.plot(history.history['val_loss'], label='Loss de Validación', color='salmon', linestyle='--')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Loss (Crossentropy Binaria)')\n",
        "plt.title('Evolución del Loss durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['accuracy'], label='Accuracy de Entrenamiento', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy de Validación', color='skyblue', linestyle='--')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Evolución del Accuracy durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -Reducir embeddings a 3D con PCA\n",
        "pca = PCA(n_components=3)\n",
        "X_3d = pca.fit_transform(X)\n",
        "\n",
        "# Crear malla 3D para frontera de decisión\n",
        "h = 0.1\n",
        "x_min, x_max = X_3d[:, 0].min() - 0.5, X_3d[:, 0].max() + 0.5\n",
        "y_min, y_max = X_3d[:, 1].min() - 0.5, X_3d[:, 1].max() + 0.5\n",
        "z_min, z_max = X_3d[:, 2].min() - 0.5, X_3d[:, 2].max() + 0.5\n",
        "\n",
        "xx, yy, zz = np.meshgrid(\n",
        "    np.arange(x_min, x_max, h),\n",
        "    np.arange(y_min, y_max, h),\n",
        "    np.arange(z_min, z_max, h)\n",
        ")\n",
        "\n",
        "grid_points = np.c_[xx.ravel(), yy.ravel(), zz.ravel()]\n",
        "grid_original_dim = pca.inverse_transform(grid_points)\n",
        "Z = model.predict(grid_original_dim, verbose=0).flatten()\n",
        "\n",
        "\n",
        "# Graficar con Plotly\n",
        "num_samples = 2000\n",
        "total_population = grid_points.shape[0]\n",
        "num_samples = min(num_samples, total_population)\n",
        "\n",
        "indices = np.random.choice(total_population, size=num_samples, replace=False)\n",
        "\n",
        "sample_points = grid_points[indices]\n",
        "sample_Z = Z[indices]\n",
        "\n",
        "# Graficar\n",
        "fig = go.Figure()\n",
        "\n",
        "# Puntos de la malla (frontera de decisión)\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=sample_points[:,0],\n",
        "    y=sample_points[:,1],\n",
        "    z=sample_points[:,2],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=3,\n",
        "        color=sample_Z,\n",
        "        colorscale='RdBu',\n",
        "        opacity=0.3,\n",
        "        colorbar=dict(title='Probabilidad (Ambiguo)')\n",
        "    ),\n",
        "    name='Frontera de Decisión'\n",
        "))\n",
        "\n",
        "# Puntos reales\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=X_3d[:,0],\n",
        "    y=X_3d[:,1],\n",
        "    z=X_3d[:,2],\n",
        "    mode='markers+text',\n",
        "    marker=dict(\n",
        "        size=8,\n",
        "        color=Y,\n",
        "        colorscale='RdBu',\n",
        "        opacity=1\n",
        "    ),\n",
        "    text=[str(label) for label in labels],\n",
        "    textposition=\"top center\",\n",
        "    name='Datos reales (0: No Ambiguo, 1: Ambiguo)'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='Componente 1',\n",
        "        yaxis_title='Componente 2',\n",
        "        zaxis_title='Componente 3'\n",
        "    ),\n",
        "    title=\"Embeddings 3D y Frontera de Decisión (Clasificación Binaria)\",\n",
        "    width=900,\n",
        "    height=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Ua6VjvddfFMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Paso 4: Cargar dataset de prueba\n",
        "# -----------------------------\n",
        "\n",
        "# Cargar archivo y preparar datos\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/dataset_prueba_263.ods\", engine=\"odf\")\n",
        "\n",
        "# Normalizar la columna 'tipo_ambiguedad' (minúsculas, sin espacios)\n",
        "df[\"tipo_ambiguedad\"] = df[\"tipo_ambiguedad\"].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Tipos que se consideran ambiguos\n",
        "tipos_ambiguos = [\"semántica\", \"pragmática\", \"sintáctica\", \"léxica\",\n",
        "                  \"semantica\", \"pragmatica\", \"sintantica\", \"lexica\"]\n",
        "\n",
        "# Crear columna binaria 'ambiguo' (1 si es ambiguo, 0 si no)\n",
        "df[\"ambiguo\"] = df[\"tipo_ambiguedad\"].apply(lambda x: 1 if x in tipos_ambiguos else 0)\n",
        "\n",
        "# Crear la estructura de prueba\n",
        "requerimientos_prueba = [\n",
        "    {\"requerimiento\": req, \"ambiguo\": amb, \"tipo\": tipo}\n",
        "    for req, amb, tipo in zip(df[\"requerimiento\"], df[\"ambiguo\"], df[\"tipo_ambiguedad\"])\n",
        "]"
      ],
      "metadata": {
        "id": "lmLXncwZgHCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Paso 5: Probar el modelo\n",
        "# -----------------------------\n",
        "\n",
        "total_aciertos = 0\n",
        "total_fallos = 0\n",
        "\n",
        "# Contar cuántos datos hay por tipo\n",
        "total_por_tipo = df[\"tipo_ambiguedad\"].value_counts().to_dict()\n",
        "\n",
        "# Inicializar diccionario de aciertos por tipo\n",
        "aciertos_por_tipo = {tipo: 0 for tipo in df[\"tipo_ambiguedad\"].unique()}\n",
        "\n",
        "# Inicializar contadores de VN, VP, FN, FP\n",
        "VN = 0\n",
        "VP = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for req in requerimientos_prueba:\n",
        "    texto = req[\"requerimiento\"]\n",
        "    tipo = req[\"tipo\"]\n",
        "    real_label = req[\"ambiguo\"]\n",
        "\n",
        "    # Generar embedding\n",
        "    vec = embedder.encode([texto])\n",
        "\n",
        "    # Predicción\n",
        "    pred_prob = model.predict(vec)[0][0]\n",
        "    pred_label = 1 if pred_prob > 0.5 else 0\n",
        "\n",
        "    # Comparar con el valor real\n",
        "    if pred_label == real_label:\n",
        "        total_aciertos += 1\n",
        "        aciertos_por_tipo[tipo] = aciertos_por_tipo.get(tipo, 0) + 1\n",
        "        if pred_label == 1:\n",
        "            VP += 1\n",
        "        else:\n",
        "            VN += 1\n",
        "    else:\n",
        "        total_fallos += 1\n",
        "        if pred_label == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "\n",
        "    # Mostrar detalle por requerimiento\n",
        "    resultado = \"Ambiguo\" if pred_label == 1 else \"No ambiguo\"\n",
        "    real = \"Ambiguo\" if real_label == 1 else \"No ambiguo\"\n",
        "    print(f\"Requerimiento: {texto}\")\n",
        "    print(f\" → Predicción: {resultado} (prob={pred_prob:.2f}) | Real: {real} | Tipo: {tipo}\\n\")\n",
        "\n",
        "# Resultados totales\n",
        "total = total_aciertos + total_fallos\n",
        "porc_aciertos = (total_aciertos / total) * 100\n",
        "porc_fallos = (total_fallos / total) * 100\n",
        "\n",
        "print(\"\\n===============================\")\n",
        "print(f\"✅ Total de aciertos: {total_aciertos} ({porc_aciertos:.2f}%)\")\n",
        "print(f\"❌ Total de fallos: {total_fallos} ({porc_fallos:.2f}%)\")\n",
        "print(\"===============================\\n\")\n",
        "\n",
        "# Mostrar métricas de VN, VP, FN, FP\n",
        "print(\"📊 Matriz de confusión:\")\n",
        "print(f\" - VP (Verdaderos positivos): {VP}\")\n",
        "print(f\" - VN (Verdaderos negativos): {VN}\")\n",
        "print(f\" - FP (Falsos positivos): {FP}\")\n",
        "print(f\" - FN (Falsos negativos): {FN}\\n\")\n",
        "\n",
        "# Aciertos por tipo de ambigüedad\n",
        "print(\"📊 Aciertos por tipo de ambigüedad:\")\n",
        "for tipo in aciertos_por_tipo.keys():\n",
        "    aciertos = aciertos_por_tipo[tipo]\n",
        "    total_tipo = total_por_tipo.get(tipo, 0)\n",
        "    if total_tipo > 0:\n",
        "        porcentaje = (aciertos / total_tipo) * 100\n",
        "        print(f\" - {tipo}: {aciertos} aciertos / {total_tipo} casos ({porcentaje:.2f}%)\")\n",
        "    else:\n",
        "        print(f\" - {tipo}: sin casos en el dataset\")\n",
        "\n",
        "# Calcular métricas avanzadas (Precisión, Recall, F1-Score)\n",
        "\n",
        "if (VP + FP) > 0:\n",
        "    precision = VP / (VP + FP)\n",
        "else:\n",
        "    precision = 0\n",
        "\n",
        "if (VP + FN) > 0:\n",
        "    recall = VP / (VP + FN)\n",
        "else:\n",
        "    recall = 0\n",
        "\n",
        "if (precision + recall) > 0:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "else:\n",
        "    f1_score = 0\n",
        "\n",
        "print(\"\\n📊 Métricas de Clasificación:\")\n",
        "print(f\" - Precisión: {precision:.2f}\")\n",
        "print(f\" - Recall (Exhaustividad): {recall:.2f}\")\n",
        "print(f\" - F1-Score: {f1_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "PkjUax6QgcG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}